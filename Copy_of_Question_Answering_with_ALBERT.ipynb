{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "frTeTcy4WdbY"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOAoUwBFMQCg"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers \\\n",
        "&& cd transformers \\\n",
        "&& git checkout a3085020ed0d81d4903c50967687192e3101e770 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRZned-8WJrj"
      },
      "source": [
        "!pip install ./transformers\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI6e-PfOXSnO"
      },
      "source": [
        "!mkdir dataset \\\n",
        "&& cd dataset \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json \\\n",
        "&& wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Eg53t3QXZAb"
      },
      "source": [
        "!export SQUAD_DIR=/content/dataset \\\n",
        "&& python transformers/examples/run_squad.py \\\n",
        "  --model_type albert \\\n",
        "  --model_name_or_path albert-base-v2 \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_lower_case \\\n",
        "  --train_file $SQUAD_DIR/train-v2.0.json \\\n",
        "  --predict_file $SQUAD_DIR/dev-v2.0.json \\\n",
        "  --per_gpu_train_batch_size 12 \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 1.0 \\\n",
        "  --max_seq_length 384 \\\n",
        "  --doc_stride 128 \\\n",
        "  --output_dir /content/model_output \\\n",
        "  --save_steps 1000 \\\n",
        "  --threads 4 \\\n",
        "  --version_2_with_negative "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp0Pq9z9Y4S0",
        "cellView": "code"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import (\n",
        "    AlbertConfig,\n",
        "    AlbertForQuestionAnswering,\n",
        "    AlbertTokenizer,\n",
        "    squad_convert_examples_to_features\n",
        ")\n",
        "\n",
        "from transformers.data.processors.squad import SquadResult, SquadV2Processor, SquadExample\n",
        "\n",
        "from transformers.data.metrics.squad_metrics import compute_predictions_logits\n",
        "\n",
        "# READER NOTE: Set this flag to use own model, or use pretrained model in the Hugging Face repository\n",
        "use_own_model = False\n",
        "\n",
        "if use_own_model:\n",
        "  model_name_or_path = \"/content/model_output\"\n",
        "else:\n",
        "  model_name_or_path = \"ktrapeznikov/albert-xlarge-v2-squad-v2\"\n",
        "\n",
        "output_dir = \"\"\n",
        "\n",
        "# Config\n",
        "n_best_size = 1\n",
        "max_answer_length = 30\n",
        "do_lower_case = True\n",
        "null_score_diff_threshold = 0.0\n",
        "\n",
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()\n",
        "\n",
        "# Setup model\n",
        "config_class, model_class, tokenizer_class = (\n",
        "    AlbertConfig, AlbertForQuestionAnswering, AlbertTokenizer)\n",
        "config = config_class.from_pretrained(model_name_or_path)\n",
        "tokenizer = tokenizer_class.from_pretrained(\n",
        "    model_name_or_path, do_lower_case=True)\n",
        "model = model_class.from_pretrained(model_name_or_path, config=config)\n",
        "\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "processor = SquadV2Processor()\n",
        "\n",
        "def run_prediction(question_texts, context_text):\n",
        "    \"\"\"Setup function to compute predictions\"\"\"\n",
        "    examples = []\n",
        "\n",
        "    for i, question_text in enumerate(question_texts):\n",
        "        example = SquadExample(\n",
        "            qas_id=str(i),\n",
        "            question_text=question_text,\n",
        "            context_text=context_text,\n",
        "            answer_text=None,\n",
        "            start_position_character=None,\n",
        "            title=\"Predict\",\n",
        "            is_impossible=False,\n",
        "            answers=None,\n",
        "        )\n",
        "\n",
        "        examples.append(example)\n",
        "\n",
        "    features, dataset = squad_convert_examples_to_features(\n",
        "        examples=examples,\n",
        "        tokenizer=tokenizer,\n",
        "        max_seq_length=384,\n",
        "        doc_stride=128,\n",
        "        max_query_length=64,\n",
        "        is_training=False,\n",
        "        return_dataset=\"pt\",\n",
        "        threads=1,\n",
        "    )\n",
        "\n",
        "    eval_sampler = SequentialSampler(dataset)\n",
        "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=10)\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for batch in eval_dataloader:\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"token_type_ids\": batch[2],\n",
        "            }\n",
        "\n",
        "            example_indices = batch[3]\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            for i, example_index in enumerate(example_indices):\n",
        "                eval_feature = features[example_index.item()]\n",
        "                unique_id = int(eval_feature.unique_id)\n",
        "\n",
        "                output = [to_list(output[i]) for output in outputs]\n",
        "\n",
        "                start_logits, end_logits = output\n",
        "                result = SquadResult(unique_id, start_logits, end_logits)\n",
        "                all_results.append(result)\n",
        "\n",
        "    output_prediction_file = \"predictions.json\"\n",
        "    output_nbest_file = \"nbest_predictions.json\"\n",
        "    output_null_log_odds_file = \"null_predictions.json\"\n",
        "\n",
        "    predictions = compute_predictions_logits(\n",
        "        examples,\n",
        "        features,\n",
        "        all_results,\n",
        "        n_best_size,\n",
        "        max_answer_length,\n",
        "        do_lower_case,\n",
        "        output_prediction_file,\n",
        "        output_nbest_file,\n",
        "        output_null_log_odds_file,\n",
        "        False,  # verbose_logging\n",
        "        True,  # version_2_with_negative\n",
        "        null_score_diff_threshold,\n",
        "        tokenizer,\n",
        "    )\n",
        "\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIQOB8vhpcKs"
      },
      "source": [
        "## 4.0 Run predictions\n",
        "\n",
        "Now for the fun part... testing out your model on different inputs. Pretty rudimentary example here. But the possibilities are endless with this function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "n96ZNb0EIBe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "tR_-_FFDIKwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "O9nDkXjUIZFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2 "
      ],
      "metadata": {
        "id": "2c7eypICIax0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fHaOQJGRIfsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfFileObj = open('/content/drive/MyDrive/Academic-Regulations.pdf', 'rb') "
      ],
      "metadata": {
        "id": "JouKQZQSInWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) "
      ],
      "metadata": {
        "id": "cZJhKYffJFCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pdfReader.numPages) "
      ],
      "metadata": {
        "id": "UTptezfoJGfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(pdfReader))"
      ],
      "metadata": {
        "id": "5NjBC2htJKZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = \"\"\n",
        "for i in range(44):\n",
        "  pageObj = pdfReader.getPage(i) \n",
        "  txt = pageObj.extractText()\n",
        "  final = final + txt\n",
        "print(type(final))"
      ],
      "metadata": {
        "id": "JxI3RmPQJMLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines = txt.split('.')\n",
        "print(lines[3])"
      ],
      "metadata": {
        "id": "-VRpDnXcJN-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final)"
      ],
      "metadata": {
        "id": "8MkMBJvtJP3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.Tensor(final)"
      ],
      "metadata": {
        "id": "lMTzahadMAPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.device('cpu:0')"
      ],
      "metadata": {
        "id": "Qr6D1VNlJ8Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdfReader = PyPDF2.PdfFileReader(\"Academic-Regulations.pdf\") \n",
        "final = \"\"\n",
        "for i in range(44):\n",
        "  pageObj = pdfReader.getPage(i) \n",
        "  txt = pageObj.extractText()\n",
        "  final = final + txt\n",
        "lines = txt.split('.')\n",
        "print(final)"
      ],
      "metadata": {
        "id": "HokRDrrraJWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-sUrcA5nXTH",
        "cellView": "code"
      },
      "source": [
        "#context = \"New Zealand (Māori: Aotearoa) is a sovereign island country in the southwestern Pacific Ocean. It has a total land area of 268,000 square kilometres (103,500 sq mi), and a population of 4.9 million. New Zealand's capital city is Wellington, and its most populous city is Auckland.\"\n",
        "pdfReader = PyPDF2.PdfFileReader(\"Academic-Regulations.pdf\") \n",
        "final = \"\"\n",
        "for i in range(44):\n",
        "  pageObj = pdfReader.getPage(i) \n",
        "  txt = pageObj.extractText()\n",
        "  final = final + txt\n",
        "lines = txt.split('.')\n",
        "\n",
        "questions = [\"How many semesters are there in a year?\", \"How many semesters are there in a year?\"]\n",
        "\n",
        "# Run method\n",
        "predictions = run_prediction(questions, final)\n",
        "\n",
        "# Print results\n",
        "for key in predictions.keys():\n",
        "  print(predictions[key])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(context))\n",
        "print(type(final))"
      ],
      "metadata": {
        "id": "49Tcvd-aWIit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "rPNHr8MTLBlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_device()"
      ],
      "metadata": {
        "id": "scLKA_QOLFlT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}